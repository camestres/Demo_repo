{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8Z6hDHy6o_4",
        "outputId": "b382e6fe-724c-4f36-a395-a0f8a377f13c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet_pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->efficientnet_pytorch) (4.4.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=786aa965e5b464d2ca2018bda553a4a9a60060e2b4196d9a60a730a72273ef0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/sample_data/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd5CAoujWpvD",
        "outputId": "b231526b-c2c9-41df-d88e-ca223e50cd4e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sample_data/data.zip\n",
            "  inflating: IdLookupTable.csv       \n",
            "  inflating: SampleSubmission.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: train_15.csv            \n",
            "  inflating: train_4.csv             \n",
            "  inflating: training.csv            \n",
            "  inflating: val_15.csv              \n",
            "  inflating: val_4.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#config\n",
        "\n",
        "import torch\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "LEARNING_RATE = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 100\n",
        "NUM_WORKERS = 0\n",
        "CHECKPOINT_FILE = \"b0_4.pth.tar\"\n",
        "PIN_MEMORY = True\n",
        "SAVE_MODEL = True\n",
        "LOAD_MODEL = True\n",
        "\n",
        "# Data augmentation for images\n",
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=96, height=96),\n",
        "        A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT, p=0.8),\n",
        "        A.Affine(shear=15, scale=1.0, mode=\"constant\", p=0.2),\n",
        "        A.RandomBrightnessContrast(contrast_limit=0.5, brightness_limit=0.5, p=0.2),\n",
        "        A.OneOf([\n",
        "            A.GaussNoise(p=0.8),\n",
        "            A.CLAHE(p=0.8),\n",
        "            A.ImageCompression(p=0.8),\n",
        "            A.RandomGamma(p=0.8),\n",
        "            A.Posterize(p=0.8),\n",
        "            A.Blur(p=0.8),\n",
        "        ], p=1.0),\n",
        "        A.OneOf([\n",
        "            A.GaussNoise(p=0.8),\n",
        "            A.CLAHE(p=0.8),\n",
        "            A.ImageCompression(p=0.8),\n",
        "            A.RandomGamma(p=0.8),\n",
        "            A.Posterize(p=0.8),\n",
        "            A.Blur(p=0.8),\n",
        "        ], p=1.0),\n",
        "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n",
        "        A.Normalize(\n",
        "            mean=[0.4897, 0.4897, 0.4897],\n",
        "            std=[0.2330, 0.2330, 0.2330],\n",
        "            max_pixel_value=255.0,\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False),\n",
        ")\n",
        "\n",
        "\n",
        "val_transforms = A.Compose(\n",
        "    [\n",
        "        A.Resize(width=96, height=96),\n",
        "        A.Normalize(\n",
        "            mean=[0.4897, 0.4897, 0.4897],\n",
        "            std=[0.2330, 0.2330, 0.2330],\n",
        "            max_pixel_value=255.0,\n",
        "        ),\n",
        "        ToTensorV2(),\n",
        "    ], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False),\n",
        ")"
      ],
      "metadata": {
        "id": "eEwJUAUcWDbD"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import config\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class FacialKeypointDataset(Dataset):\n",
        "    def __init__(self, csv_file, train=True, transform=None):\n",
        "        super().__init__()\n",
        "        self.data = pd.read_csv(csv_file)        \n",
        "        self.category_names = ['left_eye_center_x',\n",
        "          'left_eye_center_y',\n",
        "          'right_eye_center_x',\n",
        "          'right_eye_center_y',\n",
        "          'left_eye_inner_corner_x',\n",
        "          'left_eye_inner_corner_y',\n",
        "          'left_eye_outer_corner_x',\n",
        "          'left_eye_outer_corner_y',\n",
        "          'right_eye_inner_corner_x',\n",
        "          'right_eye_inner_corner_y',\n",
        "          'right_eye_outer_corner_x',\n",
        "          'right_eye_outer_corner_y',\n",
        "          'left_eyebrow_inner_end_x',\n",
        "          'left_eyebrow_inner_end_y',\n",
        "          'left_eyebrow_outer_end_x',\n",
        "          'left_eyebrow_outer_end_y',\n",
        "          'right_eyebrow_inner_end_x',\n",
        "          'right_eyebrow_inner_end_y',\n",
        "          'right_eyebrow_outer_end_x',\n",
        "          'right_eyebrow_outer_end_y',\n",
        "          'nose_tip_x',\n",
        "          'nose_tip_y',\n",
        "          'mouth_left_corner_x',\n",
        "          'mouth_left_corner_y',\n",
        "          'mouth_right_corner_x',\n",
        "          'mouth_right_corner_y',\n",
        "          'mouth_center_top_lip_x',\n",
        "          'mouth_center_top_lip_y',\n",
        "          'mouth_center_bottom_lip_x',\n",
        "          'mouth_center_bottom_lip_y'\n",
        "          ]\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):        \n",
        "        if self.train:\n",
        "            image = np.array(self.data.iloc[index, 30].split()).astype(np.float32)\n",
        "            labels = np.array(self.data.iloc[index, :30].tolist())\n",
        "            labels[np.isnan(labels)] = -1            \n",
        "        else:\n",
        "            image = np.array(self.data.iloc[index, 1].split()).astype(np.float32)\n",
        "            labels = np.zeros(30)\n",
        "\n",
        "        ignore_indices = labels == -1\n",
        "        labels = labels.reshape(15, 2)\n",
        "\n",
        "        if self.transform:\n",
        "            image = np.repeat(image.reshape(96, 96, 1), 3, 2).astype(np.uint8)\n",
        "            augmentations = self.transform(image=image, keypoints=labels)\n",
        "            image = augmentations[\"image\"]\n",
        "            labels = augmentations[\"keypoints\"]\n",
        "\n",
        "        labels = np.array(labels).reshape(-1)\n",
        "        labels[ignore_indices] = -1\n",
        "\n",
        "        return image, labels.astype(np.float32)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ds = FacialKeypointDataset(csv_file=\"train_15.csv\", train=True, transform=val_transforms)\n",
        "    loader = DataLoader(ds, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "    for idx, (x,y) in enumerate(loader):\n",
        "        plt.imshow(x[0][0].detach().cpu().numpy(), cmap='gray')\n",
        "        plt.plot(y[0][0::2].detach().cpu().numpy(), y[0][1::2].detach().cpu().numpy(), \"go\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "jYLuX1Eb7HBN",
        "outputId": "8f9be1b1-1aad-4073-c68b-877ce5a49aa6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-39a3bb8c5c9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"go\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-39a3bb8c5c9c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'split'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utils\n",
        "\n",
        "# import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# import config\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_submission(loader, dataset, model_15, model_4):\n",
        "    model_15.eval()\n",
        "    model_4.eval()\n",
        "    id_lookup = pd.read_csv(\"data/IdLookupTable.csv\")\n",
        "    predictions = []\n",
        "    image_id = 1\n",
        "\n",
        "    for image, label in tqdm(loader):\n",
        "        image = image.to(DEVICE)\n",
        "        preds_15 = torch.clip(model_15(image).squeeze(0), 0.0, 96.0)\n",
        "        preds_4 = torch.clip(model_4(image).squeeze(0), 0.0, 96.0)\n",
        "        feature_names = id_lookup.loc[id_lookup[\"imageId\"] == image_id][\"FeatureName\"]\n",
        "\n",
        "        for feature_name in feature_names:\n",
        "            feature_index = dataset.category_names.index(feature_name)\n",
        "            if feature_names.shape[0] < 10:\n",
        "                predictions.append(preds_4[feature_index].item())\n",
        "            else:\n",
        "                predictions.append(preds_15[feature_index].item())\n",
        "\n",
        "        image_id += 1\n",
        "\n",
        "    df = pd.DataFrame({\"Rowid\": np.arrange(1, len(predictions)+1), \"Location\": predictions})\n",
        "    df.to_csv(\"submission.csv\", index=False)\n",
        "    model_15.train()\n",
        "    model_4.train()\n",
        "\n",
        "def get_rmse(loader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    num_examples = 0\n",
        "    losses = []\n",
        "    for batch_idx, (data, targets) in enumerate(loader):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        #forwars\n",
        "        scores = model(data)\n",
        "        loss = loss_fn(scores[targets != 1], targets[targets != 1])\n",
        "        num_examples += scores[targets != 1].shape[0]\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    model.train()\n",
        "    print(f\"loss on val: {(sum(losses)/num_examples)**0.5}\")\n",
        "\n",
        "\n",
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "    print(\"=> Saving checkpoint\")\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(checkpoint, model, optimizer, lr):\n",
        "    print(\"=> Loading checkpoint\")\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group[\"lr\"] = lr"
      ],
      "metadata": {
        "id": "Xy6gOSFQ8jXz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "\n",
        "import torch\n",
        "# from dataset import FacialKeypointDataset\n",
        "from torch import nn, optim\n",
        "import os\n",
        "# import config\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "# from utils import (\n",
        "#     load_checkpoint,\n",
        "#     save_checkpoint,\n",
        "#     get_rmse,\n",
        "#     get_submission\n",
        "# )\n",
        "\n",
        "def train_one_epoch(loader, model, optimizer, loss_fn, scaler, device):\n",
        "    losses = []\n",
        "    loop = tqdm(loader)\n",
        "    num_examples = 0\n",
        "    for batch_idx, (data, targets) in enumerate(loop):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        #forward\n",
        "        scores = model(data)\n",
        "        scores[targets == -1] = -1\n",
        "        loss = loss_fn(scores, targets)\n",
        "        num_examples += torch.numel(scores[targets != -1])\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        #backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Loss average over epoch: {(sum(losses)/num_examples)**0.5}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    train_ds = FacialKeypointDataset(\n",
        "        csv_file=\"data/train_4.csv\",\n",
        "        transform=train_transforms,\n",
        "    )\n",
        "    train_loader = DataLoader(\n",
        "        train_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=BATCH_SIZE,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    val_ds = FacialKeypointDataset(\n",
        "        transform=val_transforms,\n",
        "        csv_file=\"data/val_4.csv\",\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_ds,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        num_workers=BATCH_SIZE,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    test_ds = FacialKeypointDataset(\n",
        "        csv_file=\"data/test.csv\",\n",
        "        transform=val_transforms,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_ds,\n",
        "        batch_size=1,\n",
        "        num_workers=BATCH_SIZE,\n",
        "        pin_memory=PIN_MEMORY,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    loss_fn = nn.MSELoss(reduction=\"sum\")\n",
        "    model = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
        "    model._fc = nn.Linear(1280, 30)\n",
        "    model = model.to(DEVICE)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    model_4 = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
        "    model_4._fc = nn.Linear(1280, 30)\n",
        "    model_15 = EfficientNet.from_pretrained(\"efficientnet-b0\")\n",
        "    model_15._fc = nn.Linear(1280, 30)\n",
        "    model_4 = model_4.to(DEVICE)\n",
        "    model_15 = model_15.to(DEVICE)\n",
        "\n",
        "    if LOAD_MODEL and CHECKPOINT_FILE in os.listdir():\n",
        "        load_checkpoint(torch.load(CHECKPOINT_FILE), model, optimizer, LEARNING_RATE)\n",
        "        load_checkpoint(torch.load(\"b0_4.pth.tar\"), model_4, optimizer, LEARNING_RATE)\n",
        "        load_checkpoint(torch.load(\"b0_15.pth.tar\"), model_15, optimizer, LEARNING_RATE)\n",
        "\n",
        "    get_submission(test_loader, test_ds, model_15, model_4)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        get_rmse(val_loader, model, loss_fn, DEVICE)\n",
        "        train_one_epoch(train_loader, model, optimizer, loss_fn, scaler, DEVICE)\n",
        "\n",
        "        #get on validation\n",
        "        if SAVE_MODEL:\n",
        "            checkpoint = {\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }\n",
        "            save_checkpoint(checkpoint, filename=CHECKPOINT_FILE)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "OtjrOW5q6vl6",
        "outputId": "e3c309bc-a6e0-41a2-e757-d6b6c70c4627"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1e86e2cd6fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-1e86e2cd6fde>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     train_ds = FacialKeypointDataset(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mcsv_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/train_4.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_transforms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FacialKeypointDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ls7Uql0kBgKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}